import sys, time
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job



## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, ['JOB_NAME'])

#创建任务，spark session等
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

#load table from S3
title_basics = glueContext.create_dynamic_frame.from_catalog(database = "test", table_name = "title_basics_new_csv")

#create temp table in spark
title_basics.toDF().createOrReplaceTempView("title_basics")


#获取Glue的日志句柄
logger = glueContext.get_logger()

#记录规则执行开始时间
start_total = time.perf_counter()

#execute title_basics CFD rule
start_rule = time.perf_counter()
rule1 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle WHERE t0.titletype <> t1.titletype"), glueContext, "rule1")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule1, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule1: " + str(rule1.count()))

start_rule = time.perf_counter()
rule2 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle WHERE t0.originaltitle <> t1.originaltitle"), glueContext, "rule2")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule2, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule2: " + str(rule2.count()))

start_rule = time.perf_counter()
rule3 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle WHERE t0.primarytitle <> t1.primarytitle"), glueContext, "rule3")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule3, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule3: " + str(rule3.count()))

start_rule = time.perf_counter()
rule4 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle WHERE t0.titletype <> t1.titletype"), glueContext, "rule4")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule4, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule4: " + str(rule4.count()))

start_rule = time.perf_counter()
rule5 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle WHERE t0.titletype <> 'tvEpisode'"), glueContext, "rule5")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule5, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule5: " + str(rule5.count()))

start_rule = time.perf_counter()
rule6 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.endyear = t1.endyear WHERE t0.titletype <> t1.titletype"), glueContext, "rule6")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule6, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule6: " + str(rule6.count()))

start_rule = time.perf_counter()
rule7 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.tconst = t1.tconst WHERE t0.endyear <> t1.endyear"), glueContext, "rule7")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule7, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule7: " + str(rule7.count()))

start_rule = time.perf_counter()
rule8 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.tconst = t1.tconst WHERE t0.primarytitle <> t1.primarytitle"), glueContext, "rule8")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule8, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule8: " + str(rule8.count()))

start_rule = time.perf_counter()
rule9 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.tconst = t1.tconst WHERE t0.originaltitle <> t1.originaltitle"), glueContext, "rule9")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule9, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule9: " + str(rule9.count()))

start_rule = time.perf_counter()
rule10 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.endyear = t1.endyear WHERE t0.tconst <> t1.tconst"), glueContext, "rule10")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule10, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule10: " + str(rule10.count()))

start_rule = time.perf_counter()
rule11 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.tconst = t1.tconst WHERE t0.titletype <> t1.titletype"), glueContext, "rule11")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule11, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule11: " + str(rule11.count()))

start_rule = time.perf_counter()
rule12 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.primarytitle = t1.primarytitle WHERE t0.genres <> t1.genres"), glueContext, "rule12")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule12, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule12: " + str(rule12.count()))

start_rule = time.perf_counter()
rule13 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.originaltitle = t1.originaltitle WHERE t0.genres <> t1.genres"), glueContext, "rule13")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule13, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule13: " + str(rule13.count()))

start_rule = time.perf_counter()
rule14 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.endyear = t1.endyear WHERE t0.startyear <> t1.startyear"), glueContext, "rule14")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule14, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule14: " + str(rule14.count()))

start_rule = time.perf_counter()
rule15 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.originaltitle = t1.originaltitle WHERE t0.startyear <> t1.startyear"), glueContext, "rule15")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule15, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule15: " + str(rule15.count()))

start_rule = time.perf_counter()
rule16 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.primarytitle = t1.primarytitle WHERE t0.startyear <> t1.startyear"), glueContext, "rule16")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule16, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule16: " + str(rule16.count()))

start_rule = time.perf_counter()
rule17 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.endyear = t1.endyear WHERE t0.runtimeminutes <> t1.runtimeminutes"), glueContext, "rule17")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule17, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule17: " + str(rule17.count()))

start_rule = time.perf_counter()
rule18 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.endyear = t1.endyear WHERE t0.genres <> t1.genres"), glueContext, "rule18")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule18, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule18: " + str(rule18.count()))

start_rule = time.perf_counter()
rule19 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.startyear = t1.startyear AND t0.primarytitle = t1.primarytitle WHERE t0.runtimeminutes <> t1.runtimeminutes"), glueContext, "rule19")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule19, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule19: " + str(rule19.count()))

start_rule = time.perf_counter()
rule20 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.startyear = t1.startyear AND t0.originaltitle = t1.originaltitle WHERE t0.runtimeminutes <> t1.runtimeminutes"), glueContext, "rule20")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule20, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule20: " + str(rule20.count()))

start_rule = time.perf_counter()
rule21 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.endyear = t1.endyear WHERE t0.tconst <> t1.tconst"), glueContext, "rule21")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule21, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule21: " + str(rule21.count()))

start_rule = time.perf_counter()
rule22 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.primarytitle = t1.primarytitle WHERE t0.endyear <> t1.endyear"), glueContext, "rule22")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule22, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule22: " + str(rule22.count()))

start_rule = time.perf_counter()
rule23 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.endyear = t1.endyear WHERE t0.runtimeminutes <> t1.runtimeminutes"), glueContext, "rule23")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule23, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule23: " + str(rule23.count()))

start_rule = time.perf_counter()
rule24 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.endyear = t1.endyear WHERE t0.primarytitle <> t1.primarytitle"), glueContext, "rule24")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule24, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule24: " + str(rule24.count()))

start_rule = time.perf_counter()
rule25 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.endyear = t1.endyear WHERE t0.primarytitle <> t1.primarytitle"), glueContext, "rule25")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule25, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule25: " + str(rule25.count()))

start_rule = time.perf_counter()
rule26 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.endyear = t1.endyear WHERE t0.genres <> t1.genres"), glueContext, "rule26")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule26, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule26: " + str(rule26.count()))

start_rule = time.perf_counter()
rule27 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.startyear = t1.startyear AND t0.primarytitle = t1.primarytitle WHERE t0.tconst <> t1.tconst"), glueContext, "rule27")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule27, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule27: " + str(rule27.count()))

start_rule = time.perf_counter()
rule28 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.originaltitle = t1.originaltitle WHERE t0.tconst <> t1.tconst"), glueContext, "rule28")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule28, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule28: " + str(rule28.count()))

start_rule = time.perf_counter()
rule29 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.tconst = t1.tconst WHERE t0.runtimeminutes <> t1.runtimeminutes"), glueContext, "rule29")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule29, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule29: " + str(rule29.count()))

start_rule = time.perf_counter()
rule30 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle AND t0.endyear = t1.endyear WHERE t0.runtimeminutes <> t1.runtimeminutes"), glueContext, "rule30")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule30, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule30: " + str(rule30.count()))

start_rule = time.perf_counter()
rule31 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.originaltitle = t1.originaltitle WHERE t0.endyear <> t1.endyear"), glueContext, "rule31")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule31, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule31: " + str(rule31.count()))

start_rule = time.perf_counter()
rule32 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.tconst = t1.tconst WHERE t0.genres <> t1.genres"), glueContext, "rule32")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule32, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule32: " + str(rule32.count()))

start_rule = time.perf_counter()
rule33 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.startyear = t1.startyear AND t0.primarytitle = t1.primarytitle WHERE t0.endyear <> t1.endyear"), glueContext, "rule33")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule33, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule33: " + str(rule33.count()))

start_rule = time.perf_counter()
rule34 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.startyear = t1.startyear AND t0.originaltitle = t1.originaltitle WHERE t0.tconst <> t1.tconst"), glueContext, "rule34")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule34, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule34: " + str(rule34.count()))

start_rule = time.perf_counter()
rule35 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.endyear = t1.endyear WHERE t0.tconst <> t1.tconst"), glueContext, "rule35")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule35, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule35: " + str(rule35.count()))

start_rule = time.perf_counter()
rule36 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.runtimeminutes = t1.runtimeminutes AND t0.primarytitle = t1.primarytitle WHERE t0.tconst <> t1.tconst"), glueContext, "rule36")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule36, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule36: " + str(rule36.count()))

start_rule = time.perf_counter()
rule37 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.endyear = t1.endyear WHERE t0.originaltitle <> t1.originaltitle"), glueContext, "rule37")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule37, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule37: " + str(rule37.count()))

start_rule = time.perf_counter()
rule38 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.endyear = t1.endyear WHERE t0.startyear <> t1.startyear"), glueContext, "rule38")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule38, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule38: " + str(rule38.count()))

start_rule = time.perf_counter()
rule39 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle AND t0.endyear = t1.endyear WHERE t0.startyear <> t1.startyear"), glueContext, "rule39")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule39, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule39: " + str(rule39.count()))

start_rule = time.perf_counter()
rule40 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.endyear = t1.endyear WHERE t0.startyear <> t1.startyear"), glueContext, "rule40")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule40, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule40: " + str(rule40.count()))

# #记录CFD规则执行时间
end_CFD = time.perf_counter()
logger.info("CFD execution time: {}s".format(end_CFD-start_total))

# execute title_basics MD rule
start_rule = time.perf_counter()
rule41 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.genres = t1.genres WHERE t0.titletype <> t1.titletype"), glueContext, "rule41")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule41, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule41: " + str(rule41.count()))

start_rule = time.perf_counter()
rule42 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle AND t0.genres = t1.genres WHERE t0.titletype <> t1.titletype"), glueContext, "rule42")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule42, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule42: " + str(rule42.count()))

start_rule = time.perf_counter()
rule43 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.startyear = t1.startyear WHERE t0.titletype <> t1.titletype"), glueContext, "rule43")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule43, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule43: " + str(rule43.count()))

start_rule = time.perf_counter()
rule44 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle AND t0.startyear = t1.startyear AND t0.genres = t1.genres WHERE t0.isadult <> t1.isadult"), glueContext, "rule44")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule44, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule44: " + str(rule44.count()))

start_rule = time.perf_counter()
rule45 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.originaltitle = t1.originaltitle AND t0.runtimeminutes = t1.runtimeminutes AND t0.genres = t1.genres WHERE t0.titletype <> t1.titletype"), glueContext, "rule45")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule45, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule45: " + str(rule45.count()))

start_rule = time.perf_counter()
rule46 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.primarytitle = t1.primarytitle AND t0.genres = t1.genres WHERE t0.isadult <> t1.isadult"), glueContext, "rule46")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule46, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule46: " + str(rule46.count()))

start_rule = time.perf_counter()
rule47 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle AND t0.startyear = t1.startyear WHERE t0.titletype <> t1.titletype"), glueContext, "rule47")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule47, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule47: " + str(rule47.count()))

start_rule = time.perf_counter()
rule48 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle AND t0.startyear = t1.startyear AND t0.genres = t1.genres WHERE t0.titletype <> t1.titletype"), glueContext, "rule48")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule48, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule48: " + str(rule48.count()))

start_rule = time.perf_counter()
rule49 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.genres = t1.genres AND t0.runtimeminutes = t1.runtimeminutes AND t0.startyear = t1.startyear WHERE t0.isadult <> t1.isadult"), glueContext, "rule49")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule49, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule49: " + str(rule49.count()))

start_rule = time.perf_counter()
rule50 = title_basics.fromDF(spark.sql("SELECT * FROM title_basics t0 INNER JOIN title_basics t1 ON t0.originaltitle = t1.originaltitle AND t0.isadult = t1.isadult AND t0.runtimeminutes = t1.runtimeminutes AND t0.genres = t1.genres WHERE t0.startyear <> t1.startyear"), glueContext, "rule50")
middle_rule = time.perf_counter()
glueContext.write_dynamic_frame.from_options(frame = rule50, connection_type = "s3", connection_options = {"path": "s3://retest/test_results/title_basics"}, format = "json")
end_rule = time.perf_counter()
logger.info("rule execution time: {}s".format(middle_rule-start_rule))
logger.info("file written time: {}s".format(end_rule-middle_rule))
logger.info("title_basics rule50: " + str(rule50.count()))



#记录规则执行结束时间
end_total = time.perf_counter()

#记录MD规则执行时间
logger.info("MD execution time: {}s".format(end_total-end_CFD))

#记录规则执行总时间
logger.info("Total execution time: {}s".format(end_total-start_total))





#提交任务执行
job.commit()